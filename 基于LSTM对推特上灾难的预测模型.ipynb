{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMNjHLdtjbmHapg84Ococ96",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chenbrilliancesol/machine-learning/blob/main/%E5%9F%BA%E4%BA%8ELSTM%E5%AF%B9%E6%8E%A8%E7%89%B9%E4%B8%8A%E7%81%BE%E9%9A%BE%E7%9A%84%E9%A2%84%E6%B5%8B%E6%A8%A1%E5%9E%8B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qU839zQBBtIq",
        "outputId": "faeb3980-43b8-4c3c-ed09-8c304c5b7256"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 78ms/step - accuracy: 0.6539 - loss: 0.6015 - val_accuracy: 0.8030 - val_loss: 0.4426\n",
            "Epoch 2/10\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 80ms/step - accuracy: 0.8760 - loss: 0.3167 - val_accuracy: 0.8102 - val_loss: 0.4559\n",
            "Epoch 3/10\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 81ms/step - accuracy: 0.9236 - loss: 0.2096 - val_accuracy: 0.7991 - val_loss: 0.5515\n",
            "Epoch 4/10\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 79ms/step - accuracy: 0.9525 - loss: 0.1432 - val_accuracy: 0.7827 - val_loss: 0.6319\n",
            "Epoch 5/10\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 78ms/step - accuracy: 0.9647 - loss: 0.0958 - val_accuracy: 0.7708 - val_loss: 0.8223\n",
            "Epoch 6/10\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 76ms/step - accuracy: 0.9731 - loss: 0.0720 - val_accuracy: 0.7492 - val_loss: 1.0094\n",
            "Epoch 7/10\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 75ms/step - accuracy: 0.9736 - loss: 0.0639 - val_accuracy: 0.7656 - val_loss: 1.2136\n",
            "Epoch 8/10\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 78ms/step - accuracy: 0.9794 - loss: 0.0493 - val_accuracy: 0.7754 - val_loss: 1.1076\n",
            "Epoch 9/10\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 79ms/step - accuracy: 0.9783 - loss: 0.0456 - val_accuracy: 0.7623 - val_loss: 1.1035\n",
            "Epoch 10/10\n",
            "\u001b[1m191/191\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 78ms/step - accuracy: 0.9790 - loss: 0.0429 - val_accuracy: 0.7649 - val_loss: 1.3007\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
            "Validation F1 Score: 0.717219589257504\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "import re\n",
        "\n",
        "# 1. 加载数据\n",
        "train_df = pd.read_csv(\"/content/train.csv\")\n",
        "test_df = pd.read_csv(\"/content/test.csv\")\n",
        "\n",
        "# 2. 简单的文本清洗\n",
        "def clean_text(text):\n",
        "    text = text.lower()  # 小写化\n",
        "    text = re.sub(r\"http\\S+\", \"\", text)  # 移除URL\n",
        "    text = re.sub(r\"@\\w+\", \"\", text)  # 移除@提及\n",
        "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text)  # 移除非字母数字字符，保留空格\n",
        "    return text\n",
        "\n",
        "train_df['cleaned_text'] = train_df['text'].apply(clean_text)\n",
        "test_df['cleaned_text'] = test_df['text'].apply(clean_text)\n",
        "\n",
        "# 3. 准备文本数据\n",
        "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")  # 处理未见过的词\n",
        "tokenizer.fit_on_texts(train_df['cleaned_text'])\n",
        "\n",
        "train_sequences = tokenizer.texts_to_sequences(train_df['cleaned_text'])\n",
        "test_sequences = tokenizer.texts_to_sequences(test_df['cleaned_text'])\n",
        "\n",
        "max_length = 50  # 设定一个序列最大长度\n",
        "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding='post', truncating='post')\n",
        "test_padded = pad_sequences(test_sequences, maxlen=max_length, padding='post', truncating='post')\n",
        "\n",
        "# 4. 构建LSTM模型\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=10000, output_dim=128, input_length=max_length),  # 词嵌入层\n",
        "    Bidirectional(LSTM(64, return_sequences=False)),  # 双向LSTM\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')  # 二分类输出\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])  # 注意：Kaggle评估指标是F1，训练时监控accuracy更直观，但最终要用F1评估\n",
        "\n",
        "# 5. 划分训练集和验证集\n",
        "X_train, X_val, y_train, y_val = train_test_split(train_padded, train_df['target'], test_size=0.2, random_state=42)\n",
        "\n",
        "# 6. 训练模型\n",
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=32,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    verbose=1)\n",
        "\n",
        "# 7. 在验证集上预测并计算F1分数（这是比赛评估指标）\n",
        "y_val_pred = (model.predict(X_val) > 0.5).astype(\"int32\")\n",
        "f1 = f1_score(y_val, y_val_pred)\n",
        "print(f\"Validation F1 Score: {f1}\")\n",
        "\n",
        "# 8. 对测试集进行预测并生成提交文件\n",
        "test_pred = (model.predict(test_padded) > 0.5).astype(\"int32\")\n",
        "submission = pd.DataFrame({'id': test_df['id'], 'target': test_pred.flatten()})\n",
        "submission.to_csv('submission.csv', index=False)"
      ]
    }
  ]
}